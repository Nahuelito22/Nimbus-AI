{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac41386-74bc-40ab-8c3c-483384d548e6",
   "metadata": {},
   "source": [
    "# Recolección de imágenes satelitales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d4012-bcf3-4e45-a2a1-a481e2dab913",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Análisis de funcionalidad para posible uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623dbf5-4991-42ee-b3e6-c97df55f640a",
   "metadata": {},
   "source": [
    "Importación de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e79f47-efc3-448b-9ae2-a9e51755bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c60d861-8870-4bec-85e4-554155484136",
   "metadata": {},
   "source": [
    "Cargar csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9344e512-e885-439b-acff-e76c3c0f9bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo de eventos con horas cargado exitosamente.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>ubicacion</th>\n",
       "      <th>fuente</th>\n",
       "      <th>estacion_asignada</th>\n",
       "      <th>hora_aprox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Aeropuerto El Plumerillo (Norte de Mendoza)</td>\n",
       "      <td>researchgate.net</td>\n",
       "      <td>MENDOZA AERO, AR</td>\n",
       "      <td>22:45 - 23:20 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-03-08</td>\n",
       "      <td>Puente de Hierro (Guaymallén)</td>\n",
       "      <td>argentina.gob.ar</td>\n",
       "      <td>MENDOZA AERO, AR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-02-14</td>\n",
       "      <td>Luján de Cuyo</td>\n",
       "      <td>eluniverso.com</td>\n",
       "      <td>MENDOZA AERO, AR</td>\n",
       "      <td>Tarde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-02-12</td>\n",
       "      <td>Luján de Cuyo (Perdriel, Vistalba)</td>\n",
       "      <td>Diario Los Andes</td>\n",
       "      <td>MENDOZA AERO, AR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-31</td>\n",
       "      <td>Ciudad de Mendoza</td>\n",
       "      <td>mdzol.com</td>\n",
       "      <td>MENDOZA AERO, AR</td>\n",
       "      <td>20:20 - 20:37 hs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha                                    ubicacion            fuente  \\\n",
       "0 2000-01-01  Aeropuerto El Plumerillo (Norte de Mendoza)  researchgate.net   \n",
       "1 2002-03-08                Puente de Hierro (Guaymallén)  argentina.gob.ar   \n",
       "2 2005-02-14                                Luján de Cuyo    eluniverso.com   \n",
       "3 2006-02-12           Luján de Cuyo (Perdriel, Vistalba)  Diario Los Andes   \n",
       "4 2008-01-31                            Ciudad de Mendoza         mdzol.com   \n",
       "\n",
       "  estacion_asignada         hora_aprox  \n",
       "0  MENDOZA AERO, AR  22:45 - 23:20 UTC  \n",
       "1  MENDOZA AERO, AR                NaN  \n",
       "2  MENDOZA AERO, AR              Tarde  \n",
       "3  MENDOZA AERO, AR                NaN  \n",
       "4  MENDOZA AERO, AR   20:20 - 20:37 hs  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargamos el archivo con las fechas y horas\n",
    "ruta_eventos = \"../data/raw/evento_granizo_limpio_hora.csv\"\n",
    "df_eventos = pd.read_csv(ruta_eventos, parse_dates=['fecha'])\n",
    "\n",
    "print(\"✅ Archivo de eventos con horas cargado exitosamente.\")\n",
    "display(df_eventos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd210758-29bc-4b58-83bc-386c83233307",
   "metadata": {},
   "source": [
    "Verificamos los horarios únicos del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c70e72d-26dc-48a6-87e2-9066ff76bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Horarios Únicos Encontrados en tu CSV ---\n",
      "['22:45 - 23:20 UTC' nan 'Tarde' '20:20 - 20:37 hs'\n",
      " 'Cerca de las 14:00 hs' '18:20 hs' 'Mediodía' 'Tarde (aprox. 18:00 hs)'\n",
      " 'Tarde (después de las 16:00 hs)' '08:30 hs' 'Noche (21:00 - 01:00 hs)'\n",
      " 'Noche' 'Tarde (desde las 13:00 hs)' 'Madrugada'\n",
      " 'Tarde-Noche (15:00 - 19:00 hs)' 'Tarde-Noche' '17:15 hs'\n",
      " 'Tarde-Noche (aprox. 20:00 hs)' 'Tarde (16:00 hs)' '16:00 - 21:30 hs'\n",
      " 'Tarde (desde las 16:00 hs)' 'Tarde (desde las 16:45 hs)'\n",
      " 'Noche (aprox. 23:00 hs)' 'Madrugada (aprox. 01:30 hs)']\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos y mostramos todos los valores únicos de la columna 'hora_aprox'\n",
    "valores_unicos_hora = df_eventos['hora_aprox'].unique()\n",
    "\n",
    "print(\"--- Horarios Únicos Encontrados en tu CSV ---\")\n",
    "print(valores_unicos_hora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d74e60-4e7a-4ded-b747-cdd52d76f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "Script para obtener imagenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b12e01-1ba1-4cb8-a766-4b6df43d91e1",
   "metadata": {},
   "source": [
    "1) La función traductora de horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "054597a8-84b7-4067-a708-234f4bbf4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hora_a_utc(texto_hora):\n",
    "    if pd.isna(texto_hora):\n",
    "        return None # Si no hay dato, devolvemos Nada\n",
    "    \n",
    "    texto_hora = str(texto_hora).lower()\n",
    "    \n",
    "    # Caso 1: La hora ya está en UTC\n",
    "    if 'utc' in texto_hora:\n",
    "        numeros = re.findall(r'\\d+', texto_hora)\n",
    "        if numeros:\n",
    "            return int(numeros[0]) # Devuelve la primera hora que encuentre\n",
    "            \n",
    "    # Caso 2: Horas de texto\n",
    "    if 'tarde' in texto_hora:\n",
    "        return 20 # 17:00 hs local -> 20:00 UTC\n",
    "    if 'noche' in texto_hora:\n",
    "        return 1 # 22:00 hs local -> 01:00 UTC del día siguiente (simplificado)\n",
    "    if 'madrugada' in texto_hora:\n",
    "        return 5 # 02:00 hs local -> 05:00 UTC\n",
    "    if 'mediodía' in texto_hora or 'mediodia' in texto_hora:\n",
    "        return 15 # 12:00 hs local -> 15:00 UTC\n",
    "        \n",
    "    # Caso 3: Extraer el primer número de la cadena\n",
    "    numeros = re.findall(r'\\d+', texto_hora)\n",
    "    if numeros:\n",
    "        hora_local = int(numeros[0])\n",
    "        # Convertimos a UTC y manejamos el cambio de día\n",
    "        hora_utc = (hora_local + 3) % 24\n",
    "        return hora_utc\n",
    "        \n",
    "    return None # Si no se pudo interpretar, devolvemos Nada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfa40d-5221-476a-bef6-fe2f43af9e4b",
   "metadata": {},
   "source": [
    "2) Configuración para la descarga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e076d09e-475b-42e8-8026-5997eecf5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando la descarga de imágenes satelitales...\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket_name = 'noaa-goes16'\n",
    "ruta_guardado = \"../data/raw/imagenes_satelitales/\"\n",
    "os.makedirs(ruta_guardado, exist_ok=True)\n",
    "print(\"Iniciando la descarga de imágenes satelitales...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c4263-cc62-4e1c-a0d8-b609283cfe64",
   "metadata": {},
   "source": [
    "3) Bucle principal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9d3c927-cce1-4ff0-ac5f-c540f636fd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> No se encontraron imágenes para 2000-01-01 a las 22:00 UTC.\n",
      "-> No se encontraron imágenes para 2005-02-14 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2008-01-31 a las 23:00 UTC.\n",
      "-> No se encontraron imágenes para 2008-11-26 a las 17:00 UTC.\n",
      "-> No se encontraron imágenes para 2008-12-18 a las 21:00 UTC.\n",
      "-> No se encontraron imágenes para 2010-09-28 a las 15:00 UTC.\n",
      "-> No se encontraron imágenes para 2011-02-23 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2011-11-20 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2012-10-29 a las 11:00 UTC.\n",
      "-> No se encontraron imágenes para 2013-02-09 a las 01:00 UTC.\n",
      "-> No se encontraron imágenes para 2014-10-26 a las 01:00 UTC.\n",
      "-> No se encontraron imágenes para 2014-12-09 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2014-12-16 a las 05:00 UTC.\n",
      "-> No se encontraron imágenes para 2015-09-25 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2016-03-01 a las 01:00 UTC.\n",
      "-> Descargando imagen para 2017-04-05 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-04-05_2000_UTC.nc\n",
      "-> Descargando imagen para 2020-11-12 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2020-11-12_2000_UTC.nc\n",
      "-> Descargando imagen para 2022-02-23 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2022-02-23_0100_UTC.nc\n",
      "-> Descargando imagen para 2024-02-28 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-02-28_0100_UTC.nc\n",
      "-> Descargando imagen para 2017-03-26 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-26_2000_UTC.nc\n",
      "-> Descargando imagen para 2018-11-25 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-25_0100_UTC.nc\n",
      "-> Descargando imagen para 2018-12-19 a las 05h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-12-19_0500_UTC.nc\n",
      "-> Descargando imagen para 2021-12-16 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-12-16_2000_UTC.nc\n",
      "-> Descargando imagen para 2023-03-08 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2023-03-08_0100_UTC.nc\n",
      "-> Descargando imagen para 2023-11-28 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2023-11-28_2000_UTC.nc\n",
      "-> Descargando imagen para 2024-01-25 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-01-25_0100_UTC.nc\n",
      "-> No se encontraron imágenes para 2007-01-27 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2010-02-12 a las 20:00 UTC.\n",
      "-> No se encontraron imágenes para 2015-11-23 a las 20:00 UTC.\n",
      "-> Descargando imagen para 2017-03-25 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-25_2000_UTC.nc\n",
      "-> Descargando imagen para 2018-11-04 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-04_2000_UTC.nc\n",
      "-> Descargando imagen para 2018-11-29 a las 19h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-29_1900_UTC.nc\n",
      "-> Descargando imagen para 2018-12-29 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-12-29_2000_UTC.nc\n",
      "-> Descargando imagen para 2019-01-01 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-01-01_2000_UTC.nc\n",
      "-> Descargando imagen para 2019-03-31 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-03-31_2000_UTC.nc\n",
      "-> Descargando imagen para 2020-02-08 a las 01h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2020-02-08_0100_UTC.nc\n",
      "-> Descargando imagen para 2021-02-17 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-02-17_2000_UTC.nc\n",
      "-> Descargando imagen para 2021-04-20 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-04-20_2000_UTC.nc\n",
      "-> Descargando imagen para 2024-01-11 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-01-11_2000_UTC.nc\n",
      "-> No se encontraron imágenes para 2017-02-02 a las 20:00 UTC.\n",
      "-> Descargando imagen para 2017-03-27 a las 20h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-27_2000_UTC.nc\n",
      "-> Descargando imagen para 2019-03-16 a las 15h UTC...\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-03-16_1500_UTC.nc\n",
      "-> No se encontraron imágenes para 2008-12-08 a las 05:00 UTC.\n",
      "\n",
      "--- Proceso de descarga finalizado ---\n"
     ]
    }
   ],
   "source": [
    "for index, evento in df_eventos.iterrows():\n",
    "    # Usamos nuestra nueva función para obtener la hora UTC\n",
    "    hora_utc = parse_hora_a_utc(evento['hora_aprox'])\n",
    "    \n",
    "    # Solo procedemos si obtuvimos una hora válida\n",
    "    if hora_utc is not None:\n",
    "        try:\n",
    "            fecha = evento['fecha']\n",
    "            año = fecha.year\n",
    "            dia_del_año = fecha.dayofyear\n",
    "            \n",
    "            prefix = f\"ABI-L2-CMIPF/{año}/{dia_del_año:03d}/{hora_utc:02d}/\"\n",
    "            response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "            \n",
    "            if 'Contents' in response:\n",
    "                key_archivo = response['Contents'][0]['Key']\n",
    "                nombre_archivo_local = f\"{ruta_guardado}{fecha.strftime('%Y-%m-%d')}_{hora_utc:02d}00_UTC.nc\"\n",
    "                \n",
    "                if not os.path.exists(nombre_archivo_local):\n",
    "                    print(f\"-> Descargando imagen para {fecha.strftime('%Y-%m-%d')} a las {hora_utc:02d}h UTC...\")\n",
    "                    s3.download_file(bucket_name, key_archivo, nombre_archivo_local)\n",
    "                    print(f\"✅ Guardado como: {nombre_archivo_local}\")\n",
    "                else:\n",
    "                    print(f\"-> Archivo ya existe: {nombre_archivo_local}. Saltando.\")\n",
    "            else:\n",
    "                print(f\"-> No se encontraron imágenes para {fecha.strftime('%Y-%m-%d')} a las {hora_utc:02d}:00 UTC.\")\n",
    "        except Exception as e:\n",
    "            print(f\"-> ERROR procesando el evento del {evento['fecha'].strftime('%Y-%m-%d')}: {e}\")\n",
    "\n",
    "print(\"\\n--- Proceso de descarga finalizado ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3e0a4-0cfb-4298-8e73-c2554df103c6",
   "metadata": {},
   "source": [
    "### Solución a errores previos en la descarga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d1d746-21fe-4e96-85ec-7ada164eaef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo de eventos con horas cargado exitosamente.\n",
      "Requirement already satisfied: boto3 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (1.40.25)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.25 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from boto3) (1.40.25)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\repositorios_locales\\proyectos_personales\\nimbus_ai\\venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.25->boto3) (1.17.0)\n",
      "\n",
      "Iniciando la descarga de imágenes satelitales...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> No se encontró la Banda 13 para 2000-01-01 a las 22:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2005-02-14 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2008-01-31 a las 23:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2008-11-26 a las 17:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2008-12-18 a las 21:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2010-09-28 a las 15:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2011-02-23 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2011-11-20 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2012-10-29 a las 11:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2013-02-09 a las 01:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2014-10-26 a las 01:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2014-12-09 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2014-12-16 a las 05:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2015-09-25 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2016-03-01 a las 01:00 UTC.\n",
      "-> Descargando: ABI-L2-CMIPF/2017/095/20/OR_ABI-L2-CMIPF-M3C13_G16_s20170952000431_e20170952011209_c20170952011278.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-04-05_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2020/317/20/OR_ABI-L2-CMIPF-M6C13_G16_s20203172000153_e20203172009473_c20203172009550.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2020-11-12_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2022/054/01/OR_ABI-L2-CMIPF-M6C13_G16_s20220540100204_e20220540109523_c20220540110018.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2022-02-23_0100_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2024/059/01/OR_ABI-L2-CMIPF-M6C13_G16_s20240590100206_e20240590109526_c20240590109589.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-02-28_0100_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2017/085/20/OR_ABI-L2-CMIPF-M3C13_G16_s20170852000416_e20170852011194_c20170852011262.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-26_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2018/329/01/OR_ABI-L2-CMIPF-M3C13_G16_s20183290100362_e20183290111140_c20183290111222.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-25_0100_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2018/353/05/OR_ABI-L2-CMIPF-M3C13_G16_s20183530500337_e20183530511115_c20183530511202.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-12-19_0500_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2021/350/20/OR_ABI-L2-CMIPF-M6C13_G16_s20213502000205_e20213502009523_c20213502010016.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-12-16_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2023/067/01/OR_ABI-L2-CMIPF-M6C13_G16_s20230670100203_e20230670109525_c20230670109596.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2023-03-08_0100_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2023/332/20/OR_ABI-L2-CMIPF-M6C13_G16_s20233322000203_e20233322009523_c20233322009591.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2023-11-28_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2024/025/01/OR_ABI-L2-CMIPF-M6C13_G16_s20240250100203_e20240250109523_c20240250109598.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-01-25_0100_UTC_C13.nc\n",
      "-> No se encontró la Banda 13 para 2007-01-27 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2010-02-12 a las 20:00 UTC.\n",
      "-> No se encontró la Banda 13 para 2015-11-23 a las 20:00 UTC.\n",
      "-> Descargando: ABI-L2-CMIPF/2017/084/20/OR_ABI-L2-CMIPF-M3C13_G16_s20170842000415_e20170842011194_c20170842011260.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-25_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2018/308/20/OR_ABI-L2-CMIPF-M3C13_G16_s20183082000369_e20183082011147_c20183082011229.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-04_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2018/333/19/OR_ABI-L2-CMIPF-M3C13_G16_s20183331900353_e20183331911132_c20183331911210.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-11-29_1900_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2018/363/20/OR_ABI-L2-CMIPF-M3C13_G16_s20183632000366_e20183632011144_c20183632011221.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2018-12-29_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2019/001/20/OR_ABI-L2-CMIPF-M3C13_G16_s20190012000363_e20190012011142_c20190012011223.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-01-01_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2019/090/20/OR_ABI-L2-CMIPF-M3C13_G16_s20190902000335_e20190902011113_c20190902011192.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-03-31_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2020/039/01/OR_ABI-L2-CMIPF-M6C13_G16_s20200390100094_e20200390109413_c20200390109497.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2020-02-08_0100_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2021/048/20/OR_ABI-L2-CMIPF-M6C13_G16_s20210482000063_e20210482009382_c20210482009475.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-02-17_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2021/110/20/OR_ABI-L2-CMIPF-M6C13_G16_s20211102000186_e20211102009505_c20211102009577.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2021-04-20_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2024/011/20/OR_ABI-L2-CMIPF-M6C13_G16_s20240112000204_e20240112009524_c20240112009598.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2024-01-11_2000_UTC_C13.nc\n",
      "-> No se encontró la Banda 13 para 2017-02-02 a las 20:00 UTC.\n",
      "-> Descargando: ABI-L2-CMIPF/2017/086/20/OR_ABI-L2-CMIPF-M3C13_G16_s20170862000380_e20170862011158_c20170862011230.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2017-03-27_2000_UTC_C13.nc\n",
      "-> Descargando: ABI-L2-CMIPF/2019/075/15/OR_ABI-L2-CMIPF-M3C13_G16_s20190751500369_e20190751511147_c20190751511226.nc\n",
      "✅ Guardado como: ../data/raw/imagenes_satelitales/2019-03-16_1500_UTC_C13.nc\n",
      "-> No se encontró la Banda 13 para 2008-12-08 a las 05:00 UTC.\n",
      "\n",
      "--- Proceso de descarga finalizado ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore import UNSIGNED  # <-- CORRECCIÓN DEL ERROR DE TIPEO\n",
    "from botocore.config import Config\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "# --- 1. Cargar tu archivo de eventos con las horas ---\n",
    "try:\n",
    "    ruta_eventos = \"../data/raw/evento_granizo_limpio_hora.csv\"\n",
    "    df_eventos = pd.read_csv(ruta_eventos, parse_dates=['fecha'])\n",
    "    print(\"✅ Archivo de eventos con horas cargado exitosamente.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: No se encontró el archivo en la ruta '{ruta_eventos}'.\")\n",
    "    df_eventos = None # Detenemos si no se encuentra el archivo\n",
    "\n",
    "if df_eventos is not None:\n",
    "    # --- 2. Instalar las librerías necesarias ---\n",
    "    !pip install boto3\n",
    "    \n",
    "    # --- 3. La Función \"Traductora\" de Horas ---\n",
    "    def parse_hora_a_utc(texto_hora):\n",
    "        if pd.isna(texto_hora):\n",
    "            return None\n",
    "        texto_hora = str(texto_hora).lower()\n",
    "        if 'utc' in texto_hora:\n",
    "            numeros = re.findall(r'\\d+', texto_hora)\n",
    "            return int(numeros[0]) if numeros else None\n",
    "        if 'tarde' in texto_hora: return 20 # 17:00 ART -> 20:00 UTC\n",
    "        if 'noche' in texto_hora: return 1  # 22:00 ART -> 01:00 UTC (+1 día)\n",
    "        if 'madrugada' in texto_hora: return 5 # 02:00 ART -> 05:00 UTC\n",
    "        if 'mediodía' in texto_hora or 'mediodia' in texto_hora: return 15 # 12:00 ART -> 15:00 UTC\n",
    "        numeros = re.findall(r'\\d+', texto_hora)\n",
    "        if numeros:\n",
    "            hora_local = int(numeros[0])\n",
    "            return (hora_local + 3) % 24\n",
    "        return None\n",
    "\n",
    "    # --- 4. Configuración para la descarga ---\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    bucket_name = 'noaa-goes16'\n",
    "    ruta_guardado = \"../data/raw/imagenes_satelitales/\"\n",
    "    os.makedirs(ruta_guardado, exist_ok=True)\n",
    "    print(\"\\nIniciando la descarga de imágenes satelitales...\")\n",
    "\n",
    "    # --- 5. Bucle principal de descarga ---\n",
    "    for index, evento in df_eventos.iterrows():\n",
    "        hora_utc = parse_hora_a_utc(evento['hora_aprox'])\n",
    "        \n",
    "        if hora_utc is not None:\n",
    "            try:\n",
    "                fecha = evento['fecha']\n",
    "                año = fecha.year\n",
    "                dia_del_año = fecha.dayofyear\n",
    "                \n",
    "                # Buscamos archivos de la Banda 13 (CMIPF)\n",
    "                prefix = f\"ABI-L2-CMIPF/{año}/{dia_del_año:03d}/{hora_utc:02d}/\"\n",
    "                response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "                \n",
    "                archivo_encontrado = None\n",
    "                if 'Contents' in response:\n",
    "                    for file in response['Contents']:\n",
    "                        if 'C13' in file['Key']: # Buscamos el identificador de la Banda 13\n",
    "                            archivo_encontrado = file['Key']\n",
    "                            break\n",
    "                \n",
    "                if archivo_encontrado:\n",
    "                    nombre_archivo_local = f\"{ruta_guardado}{fecha.strftime('%Y-%m-%d')}_{hora_utc:02d}00_UTC_C13.nc\"\n",
    "                    if not os.path.exists(nombre_archivo_local):\n",
    "                        print(f\"-> Descargando: {archivo_encontrado}\")\n",
    "                        s3.download_file(bucket_name, archivo_encontrado, nombre_archivo_local)\n",
    "                        print(f\"✅ Guardado como: {nombre_archivo_local}\")\n",
    "                    else:\n",
    "                        print(f\"-> Archivo ya existe: {nombre_archivo_local}. Saltando.\")\n",
    "                else:\n",
    "                    print(f\"-> No se encontró la Banda 13 para {fecha.strftime('%Y-%m-%d')} a las {hora_utc:02d}:00 UTC.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"-> ERROR procesando el evento del {evento['fecha'].strftime('%Y-%m-%d')}: {e}\")\n",
    "            \n",
    "            time.sleep(1) # Pequeña pausa de cortesía\n",
    "\n",
    "    print(\"\\n--- Proceso de descarga finalizado ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79370d-541a-48fd-8703-e1220d4d30c3",
   "metadata": {},
   "source": [
    "## Utilización para el proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe00bc-d131-4e15-ad91-03910d3f3e16",
   "metadata": {},
   "source": [
    "A continuación se creará una lista de eventos sobre el granizo, para luego descargar las imágenes satelitales correspondientes.\n",
    "Esto permitirá generar un dataset con imágenes satelitales que tengan la etiqueta granizo (1=Si / 0=No).\n",
    "Para su posterior uso y entrenamiento con una CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44bd70-edfc-4491-bede-d5c384b330f2",
   "metadata": {},
   "source": [
    "1) Importación de librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c5b336-8bfd-46d4-8a2b-3c609f158d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fdaf4-5960-47e3-a074-a686f3c379b9",
   "metadata": {},
   "source": [
    "2) Cargar los datasets necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eeb976e-34a5-4ace-a466-0ba34f30e79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets cargados.\n"
     ]
    }
   ],
   "source": [
    "# El dataset enriquecido, que tiene TODAS las fechas\n",
    "ruta_dataset_enriquecido = \"../data/processed/dataset_final_enriquecido.csv\"\n",
    "df_completo = pd.read_csv(ruta_dataset_enriquecido, parse_dates=['date'])\n",
    "\n",
    "# El archivo de eventos, que tiene las HORAS que investigaste\n",
    "ruta_eventos = \"../data/raw/eventos_granizo_limpio_hora.csv\"\n",
    "df_eventos = pd.read_csv(ruta_eventos, parse_dates=['fecha'])\n",
    "\n",
    "print(\"✅ Datasets cargados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c32a82-0f86-4ad6-8a48-6f3cef4abf3a",
   "metadata": {},
   "source": [
    "2) Preparar las \"Tareas Positivas\" (Días con Granizo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28cb0d4f-afc2-45a8-acd1-fbbfc6834eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se procesarán 84 eventos de granizo (positivos).\n"
     ]
    }
   ],
   "source": [
    "# Nos quedamos con las columnas que necesitamos de tu investigación\n",
    "tareas_positivas = df_eventos[['fecha', 'hora_aprox']].copy()\n",
    "tareas_positivas = tareas_positivas.rename(columns={'fecha': 'date'})\n",
    "tareas_positivas['granizo'] = 1\n",
    "print(f\"Se procesarán {len(tareas_positivas)} eventos de granizo (positivos).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa4436-8186-417d-bc98-837cc67c22c9",
   "metadata": {},
   "source": [
    "3) Preparar las \"Tareas Negativas\" (Días SIN Granizo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d920f3-20c7-4765-8650-bb3cf4ae5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los días que NO tuvieron granizo en nuestro dataset principal\n",
    "df_sin_granizo = df_completo[df_completo['granizo'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a424b6e6-cffa-4cc2-b7c1-5ed7f4a20fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se seleccionaron 300 días sin granizo (negativos).\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos una muestra aleatoria (ej. 300 días) para tener un balance\n",
    "# random_state es para que la muestra sea siempre la misma si volvemos a correr el código\n",
    "tareas_negativas = df_sin_granizo.sample(n=300, random_state=42).copy()\n",
    "# Les asignamos una hora estándar de la tarde (20:00 UTC), que es el pico de actividad\n",
    "tareas_negativas['hora_aprox'] = \"17:00 hs\" \n",
    "tareas_negativas['granizo'] = 0\n",
    "# Nos quedamos solo con las columnas que necesitamos\n",
    "tareas_negativas = tareas_negativas[['date', 'hora_aprox', 'granizo']]\n",
    "print(f\"Se seleccionaron {len(tareas_negativas)} días sin granizo (negativos).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd407db-38ec-433f-9dfa-6b90a94c1b9f",
   "metadata": {},
   "source": [
    "4) Unir Todo en una Única Lista de Tareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9aa356d-1c63-4596-9713-0bb5ed67360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "✅ Lista de tareas de descarga de imágenes creada y mezclada.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hora_aprox</th>\n",
       "      <th>granizo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-10-01</td>\n",
       "      <td>17:00 hs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-12-12</td>\n",
       "      <td>17:00 hs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>17:00 hs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>17:00 hs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>Tarde (aprox. 18:00 hs)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date               hora_aprox  granizo\n",
       "0 2004-10-01                 17:00 hs        0\n",
       "1 2005-12-12                 17:00 hs        0\n",
       "2 2019-05-20                 17:00 hs        0\n",
       "3 2019-08-11                 17:00 hs        0\n",
       "4 2021-02-17  Tarde (aprox. 18:00 hs)        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imágenes a procesar: 384\n"
     ]
    }
   ],
   "source": [
    "df_tareas_imagenes = pd.concat([tareas_positivas, tareas_negativas], ignore_index=True)\n",
    "# Mezclamos las filas para que no estén todas las positivas juntas\n",
    "df_tareas_imagenes = df_tareas_imagenes.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\\n✅ Lista de tareas de descarga de imágenes creada y mezclada.\")\n",
    "display(df_tareas_imagenes.head())\n",
    "print(f\"Total de imágenes a procesar: {len(df_tareas_imagenes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda5c80-23ba-4cb4-9c16-30f23cbf80ff",
   "metadata": {},
   "source": [
    "Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c48bd8-4208-4972-94d4-4332283d3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "771f6302-a8d1-4a5c-b698-4f7fcae53149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando la descarga de secuencias de imágenes satelitales...\n",
      "Este proceso puede tardar varias horas.\n",
      "\n",
      "Procesando evento: 2004-10-01\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2005-12-12\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2019-05-20\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2019-08-11\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-02-17\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2008-11-07\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2022-06-20\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2000-04-27\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2014-08-17\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2000-06-10\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2010-08-18\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2004-02-05\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2005-04-19\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2007-05-15\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2017-01-02\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2023-01-22\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(nombre_archivo_local):\n\u001b[32m     65\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  -> Descargando imagen para las \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhora_utc_actual\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:00 UTC...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchivo_encontrado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnombre_archivo_local\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m     \u001b[38;5;66;03m# No imprimimos \"archivo ya existe\" para no llenar la salida\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  -> No se encontraron imágenes para las \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhora_utc_actual\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:00 UTC.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\boto3\\s3\\inject.py:223\u001b[39m, in \u001b[36mdownload_file\u001b[39m\u001b[34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\boto3\\s3\\transfer.py:406\u001b[39m, in \u001b[36mS3Transfer.download_file\u001b[39m\u001b[34m(self, bucket, key, filename, extra_args, callback)\u001b[39m\n\u001b[32m    402\u001b[39m future = \u001b[38;5;28mself\u001b[39m._manager.download(\n\u001b[32m    403\u001b[39m     bucket, key, filename, extra_args, subscribers\n\u001b[32m    404\u001b[39m )\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\s3transfer\\futures.py:114\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.cancel()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\s3transfer\\futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Repositorios_Locales\\Proyectos_Personales\\Nimbus_AI\\venv\\Lib\\site-packages\\s3transfer\\futures.py:282\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[32m    273\u001b[39m \n\u001b[32m    274\u001b[39m \u001b[33;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03mfailure.\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_done_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- 1. La Función \"Traductora\" de Horas (la misma que ya teníamos) ---\n",
    "def parse_hora_a_utc(texto_hora):\n",
    "    if pd.isna(texto_hora): return None\n",
    "    texto_hora = str(texto_hora).lower()\n",
    "    if 'utc' in texto_hora:\n",
    "        numeros = re.findall(r'\\d+', texto_hora)\n",
    "        return int(numeros[0]) if numeros else None\n",
    "    if 'tarde' in texto_hora: return 20\n",
    "    if 'noche' in texto_hora: return 1\n",
    "    if 'madrugada' in texto_hora: return 5\n",
    "    if 'mediodía' in texto_hora or 'mediodia' in texto_hora: return 15\n",
    "    numeros = re.findall(r'\\d+', texto_hora)\n",
    "    if numeros:\n",
    "        hora_local = int(numeros[0])\n",
    "        return (hora_local + 3) % 24\n",
    "    return None\n",
    "\n",
    "# --- 2. Configuración para la descarga ---\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket_name = 'noaa-goes16'\n",
    "ruta_base_guardado = \"../data/raw/imagenes_satelitales/\"\n",
    "os.makedirs(ruta_base_guardado, exist_ok=True)\n",
    "\n",
    "print(\"\\nIniciando la descarga de secuencias de imágenes satelitales...\")\n",
    "print(\"Este proceso puede tardar varias horas.\")\n",
    "\n",
    "# --- 3. Bucle principal de descarga de secuencias ---\n",
    "for index, tarea in df_tareas_imagenes.iterrows():\n",
    "    fecha = tarea['date']\n",
    "    hora_central_utc = parse_hora_a_utc(tarea['hora_aprox'])\n",
    "    \n",
    "    if hora_central_utc is not None:\n",
    "        # --- Lógica de Checkpoints por Carpeta ---\n",
    "        nombre_carpeta_evento = f\"{ruta_base_guardado}{fecha.strftime('%Y-%m-%d')}_{('granizo' if tarea['granizo'] == 1 else 'no_granizo')}/\"\n",
    "        \n",
    "        # Si la carpeta existe y ya tiene 5 imágenes, la saltamos.\n",
    "        if os.path.exists(nombre_carpeta_evento) and len(os.listdir(nombre_carpeta_evento)) >= 5:\n",
    "            print(f\"\\nSecuencia para {fecha.strftime('%Y-%m-%d')} ya completa. Saltando.\")\n",
    "            continue\n",
    "        \n",
    "        os.makedirs(nombre_carpeta_evento, exist_ok=True)\n",
    "        print(f\"\\nProcesando evento: {fecha.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # --- Bucle para descargar la secuencia (-2h a +2h) ---\n",
    "        for i in range(-2, 3):\n",
    "            hora_utc_actual = (hora_central_utc + i) % 24\n",
    "            \n",
    "            try:\n",
    "                año = fecha.year\n",
    "                dia_del_año = fecha.dayofyear\n",
    "                prefix = f\"ABI-L2-CMIPF/{año}/{dia_del_año:03d}/{hora_utc_actual:02d}/\"\n",
    "                \n",
    "                response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "                \n",
    "                archivo_encontrado = None\n",
    "                if 'Contents' in response:\n",
    "                    for file in response['Contents']:\n",
    "                        if 'C13' in file['Key']: # Buscamos la Banda 13\n",
    "                            archivo_encontrado = file['Key']\n",
    "                            break\n",
    "                \n",
    "                if archivo_encontrado:\n",
    "                    nombre_archivo_local = f\"{nombre_carpeta_evento}{fecha.strftime('%Y-%m-%d')}_{hora_utc_actual:02d}00_UTC_C13.nc\"\n",
    "                    if not os.path.exists(nombre_archivo_local):\n",
    "                        print(f\"  -> Descargando imagen para las {hora_utc_actual:02d}:00 UTC...\")\n",
    "                        s3.download_file(bucket_name, archivo_encontrado, nombre_archivo_local)\n",
    "                    # No imprimimos \"archivo ya existe\" para no llenar la salida\n",
    "                else:\n",
    "                    print(f\"  -> No se encontraron imágenes para las {hora_utc_actual:02d}:00 UTC.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  -> ERROR procesando la hora {hora_utc_actual:02d}:00 UTC. Error: {e}\")\n",
    "            \n",
    "            time.sleep(1) # Pausa entre cada hora\n",
    "\n",
    "print(\"\\n--- Proceso de descarga de secuencias finalizado ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd354770-ed15-44d7-b430-c18e2ff99849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5217296b-83b9-45cf-af3d-c6e52193f26e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reconocer cantidad disponible de imágenes para días con granizo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f967f38-ac6e-4d8b-abc4-8138ccc29fdb",
   "metadata": {},
   "source": [
    "Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b89639-b0e3-4be5-9b10-08f4353b5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd87f1-26e1-4a65-bb1e-e5d1e765ac27",
   "metadata": {},
   "source": [
    "Script para traduccion de horas, comprobacion de resultados mediante aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218e23b9-be48-4a5b-acc1-4b8c3836ff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando misión de reconocimiento para eventos de granizo...\n",
      "  -> ✅ Imagen disponible para el 2017-04-05\n",
      "  -> ✅ Imagen disponible para el 2020-11-12\n",
      "  -> ✅ Imagen disponible para el 2022-02-23\n",
      "  -> ✅ Imagen disponible para el 2024-02-28\n",
      "  -> ✅ Imagen disponible para el 2017-03-26\n",
      "  -> ✅ Imagen disponible para el 2018-11-25\n",
      "  -> ✅ Imagen disponible para el 2018-12-19\n",
      "  -> ✅ Imagen disponible para el 2021-12-16\n",
      "  -> ✅ Imagen disponible para el 2023-03-08\n",
      "  -> ✅ Imagen disponible para el 2023-11-28\n",
      "  -> ✅ Imagen disponible para el 2024-01-25\n",
      "  -> ✅ Imagen disponible para el 2017-03-25\n",
      "  -> ✅ Imagen disponible para el 2018-11-04\n",
      "  -> ✅ Imagen disponible para el 2018-11-29\n",
      "  -> ✅ Imagen disponible para el 2018-12-29\n",
      "  -> ✅ Imagen disponible para el 2019-01-01\n",
      "  -> ✅ Imagen disponible para el 2019-03-31\n",
      "  -> ✅ Imagen disponible para el 2020-02-08\n",
      "  -> ✅ Imagen disponible para el 2021-02-17\n",
      "  -> ✅ Imagen disponible para el 2021-04-20\n",
      "  -> ✅ Imagen disponible para el 2024-01-11\n",
      "  -> ❌ Imagen NO disponible para el 2017-02-02\n",
      "  -> ✅ Imagen disponible para el 2017-03-27\n",
      "  -> ✅ Imagen disponible para el 2019-03-16\n",
      "\n",
      "\n",
      "--- Informe de Reconocimiento ---\n",
      "✅ Se encontraron 23 eventos de granizo con imágenes satelitales disponibles.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar tu lista de eventos y configurar la conexión ---\n",
    "ruta_eventos = \"../data/raw/eventos_granizo_limpio_hora.csv\"\n",
    "df_eventos = pd.read_csv(ruta_eventos, parse_dates=['fecha'])\n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket_name = 'noaa-goes16'\n",
    "\n",
    "# --- 2. La Función \"Traductora\" de Horas ---\n",
    "def parse_hora_a_utc(texto_hora):\n",
    "    if pd.isna(texto_hora): return None\n",
    "    texto_hora = str(texto_hora).lower()\n",
    "    if 'utc' in texto_hora:\n",
    "        numeros = re.findall(r'\\d+', texto_hora)\n",
    "        return int(numeros[0]) if numeros else None\n",
    "    if 'tarde' in texto_hora: return 20\n",
    "    if 'noche' in texto_hora: return 1\n",
    "    if 'madrugada' in texto_hora: return 5\n",
    "    if 'mediodía' in texto_hora or 'mediodia' in texto_hora: return 15\n",
    "    numeros = re.findall(r'\\d+', texto_hora)\n",
    "    if numeros:\n",
    "        hora_local = int(numeros[0])\n",
    "        return (hora_local + 3) % 24\n",
    "    return None\n",
    "\n",
    "# --- 3. Misión de Reconocimiento ---\n",
    "print(\"Iniciando misión de reconocimiento para eventos de granizo...\")\n",
    "eventos_descargables = []\n",
    "\n",
    "# Filtramos solo los eventos a partir de 2017, que es cuando el satélite empezó a operar\n",
    "for index, evento in df_eventos[df_eventos['fecha'].dt.year >= 2017].iterrows():\n",
    "    hora_utc = parse_hora_a_utc(evento['hora_aprox'])\n",
    "    \n",
    "    if hora_utc is not None:\n",
    "        fecha = evento['fecha']\n",
    "        prefix = f\"ABI-L2-CMIPF/{fecha.year}/{fecha.dayofyear:03d}/{hora_utc:02d}/\"\n",
    "        \n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "        \n",
    "        # Verificamos si se encontró algún archivo de la Banda 13\n",
    "        if 'Contents' in response and any('C13' in file['Key'] for file in response['Contents']):\n",
    "            print(f\"  -> ✅ Imagen disponible para el {fecha.strftime('%Y-%m-%d')}\")\n",
    "            eventos_descargables.append(evento)\n",
    "        else:\n",
    "            print(f\"  -> ❌ Imagen NO disponible para el {fecha.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# --- 4. Informe Final de la Misión ---\n",
    "df_eventos_descargables = pd.DataFrame(eventos_descargables)\n",
    "total_eventos_positivos = len(df_eventos_descargables)\n",
    "print(f\"\\n\\n--- Informe de Reconocimiento ---\")\n",
    "print(f\"✅ Se encontraron {total_eventos_positivos} eventos de granizo con imágenes satelitales disponibles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1436a0-e0ea-4704-99ec-f72e59a6e2fa",
   "metadata": {},
   "source": [
    "### Descarga de imagenes para eventos disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba18221-8437-484c-9df0-4201c9bc7611",
   "metadata": {},
   "source": [
    "Importar librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ac1e12-f12e-4935-9fbb-e9418b17798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b316633-7fbc-4f4d-9491-c551de77924a",
   "metadata": {},
   "source": [
    "Este script realiza 3 pasos:\n",
    "1) Cargar el Dataset Completo\n",
    "2) Crea la Lista de Tareas Final y Balanceada\n",
    "3) Script de Descarga de Secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e86115-cbc6-427d-829b-2c9b1d76a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fase 1: Misión de Reconocimiento ---\n",
      "✅ Reconocimiento finalizado. Se encontraron 23 eventos de granizo con imágenes disponibles.\n",
      "\n",
      "--- Fase 2: Creando lista de tareas final... ---\n",
      "✅ Lista de tareas final creada con 23 eventos positivos y 23 negativos.\n",
      "\n",
      "--- Fase 3: Iniciando la descarga de secuencias de imágenes satelitales ---\n",
      "Este proceso puede tardar varios minutos.\n",
      "\n",
      "Procesando evento: 2019-02-21\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-09-16\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-06-08\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2022-08-29\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-04-15\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-10-24\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-03-26\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-11-04\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2023-03-08\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2024-02-28\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-12-19\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "  -> Descargando imagen para las 04:00 UTC...\n",
      "  -> Descargando imagen para las 05:00 UTC...\n",
      "  -> Descargando imagen para las 06:00 UTC...\n",
      "  -> Descargando imagen para las 07:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-06-17\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-01-10\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-04-20\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-02-08\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-11-29\n",
      "  -> Descargando imagen para las 17:00 UTC...\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-09-09\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2019-01-01\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2023-11-28\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2019-03-31\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-04-11\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2023-06-02\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2023-07-09\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-04-05\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-09-05\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-10-02\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-11-25\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-03-25\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-06-23\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-11-12\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2023-06-20\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-03-27\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2022-02-23\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-06-26\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2022-09-20\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2019-09-12\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2024-01-25\n",
      "  -> Descargando imagen para las 23:00 UTC...\n",
      "  -> Descargando imagen para las 00:00 UTC...\n",
      "  -> Descargando imagen para las 01:00 UTC...\n",
      "  -> Descargando imagen para las 02:00 UTC...\n",
      "  -> Descargando imagen para las 03:00 UTC...\n",
      "\n",
      "Procesando evento: 2019-03-16\n",
      "  -> Descargando imagen para las 13:00 UTC...\n",
      "  -> Descargando imagen para las 14:00 UTC...\n",
      "  -> Descargando imagen para las 15:00 UTC...\n",
      "  -> Descargando imagen para las 16:00 UTC...\n",
      "  -> Descargando imagen para las 17:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-02-17\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2024-12-22\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2024-01-11\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2021-12-16\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2020-08-23\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2018-12-29\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "Procesando evento: 2017-02-12\n",
      "  -> No se encontraron imágenes para las 18:00 UTC.\n",
      "  -> No se encontraron imágenes para las 19:00 UTC.\n",
      "  -> No se encontraron imágenes para las 20:00 UTC.\n",
      "  -> No se encontraron imágenes para las 21:00 UTC.\n",
      "  -> No se encontraron imágenes para las 22:00 UTC.\n",
      "\n",
      "Procesando evento: 2021-11-28\n",
      "  -> Descargando imagen para las 18:00 UTC...\n",
      "  -> Descargando imagen para las 19:00 UTC...\n",
      "  -> Descargando imagen para las 20:00 UTC...\n",
      "  -> Descargando imagen para las 21:00 UTC...\n",
      "  -> Descargando imagen para las 22:00 UTC...\n",
      "\n",
      "--- Proceso de descarga de secuencias finalizado ---\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# FASE 1: MISIÓN DE RECONOCIMIENTO\n",
    "# ==============================================================================\n",
    "print(\"--- Fase 1: Misión de Reconocimiento ---\")\n",
    "\n",
    "# --- Función \"Traductora\" de Horas (definida una sola vez) ---\n",
    "def parse_hora_a_utc(texto_hora):\n",
    "    if pd.isna(texto_hora): return None\n",
    "    texto_hora = str(texto_hora).lower()\n",
    "    if 'utc' in texto_hora:\n",
    "        numeros = re.findall(r'\\d+', texto_hora)\n",
    "        return int(numeros[0]) if numeros else None\n",
    "    if 'tarde' in texto_hora: return 20\n",
    "    if 'noche' in texto_hora: return 1\n",
    "    if 'madrugada' in texto_hora: return 5\n",
    "    if 'mediodía' in texto_hora or 'mediodia' in texto_hora: return 15\n",
    "    numeros = re.findall(r'\\d+', texto_hora)\n",
    "    if numeros:\n",
    "        hora_local = int(numeros[0])\n",
    "        return (hora_local + 3) % 24\n",
    "    return None\n",
    "\n",
    "# --- Cargar eventos y configurar conexión ---\n",
    "try:\n",
    "    ruta_eventos = \"../data/raw/eventos_granizo_limpio_hora.csv\"\n",
    "    df_eventos_original = pd.read_csv(ruta_eventos, parse_dates=['fecha'])\n",
    "    \n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    bucket_name = 'noaa-goes16'\n",
    "\n",
    "    eventos_descargables = []\n",
    "    # Filtramos solo eventos a partir de 2017\n",
    "    for index, evento in df_eventos_original[df_eventos_original['fecha'].dt.year >= 2017].iterrows():\n",
    "        hora_utc = parse_hora_a_utc(evento['hora_aprox'])\n",
    "        if hora_utc is not None:\n",
    "            fecha = evento['fecha']\n",
    "            prefix = f\"ABI-L2-CMIPF/{fecha.year}/{fecha.dayofyear:03d}/{hora_utc:02d}/\"\n",
    "            response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "            if 'Contents' in response and any('C13' in file['Key'] for file in response['Contents']):\n",
    "                eventos_descargables.append(evento)\n",
    "\n",
    "    df_eventos_descargables = pd.DataFrame(eventos_descargables)\n",
    "    total_eventos_positivos = len(df_eventos_descargables)\n",
    "    print(f\"✅ Reconocimiento finalizado. Se encontraron {total_eventos_positivos} eventos de granizo con imágenes disponibles.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: No se encontró el archivo '{ruta_eventos}'. No se puede continuar.\")\n",
    "    total_eventos_positivos = 0\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# FASE 2: CREAR LISTA DE TAREAS\n",
    "# ==============================================================================\n",
    "if total_eventos_positivos > 0:\n",
    "    print(\"\\n--- Fase 2: Creando lista de tareas final... ---\")\n",
    "    ruta_dataset_enriquecido = \"../data/processed/dataset_final_enriquecido.csv\"\n",
    "    df_completo = pd.read_csv(ruta_dataset_enriquecido, parse_dates=['date'])\n",
    "\n",
    "    tareas_positivas = df_eventos_descargables[['fecha', 'hora_aprox']].copy()\n",
    "    tareas_positivas = tareas_positivas.rename(columns={'fecha': 'date'})\n",
    "    tareas_positivas['granizo'] = 1\n",
    "\n",
    "    df_sin_granizo = df_completo[(df_completo['granizo'] == 0) & (df_completo['date'].dt.year >= 2017)]\n",
    "    tareas_negativas = df_sin_granizo.sample(n=total_eventos_positivos, random_state=42).copy()\n",
    "    tareas_negativas['hora_aprox'] = \"17:00 hs\"\n",
    "    tareas_negativas = tareas_negativas[['date', 'hora_aprox', 'granizo']]\n",
    "\n",
    "    df_tareas_imagenes = pd.concat([tareas_positivas, tareas_negativas], ignore_index=True)\n",
    "    df_tareas_imagenes = df_tareas_imagenes.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(f\"✅ Lista de tareas final creada con {len(tareas_positivas)} eventos positivos y {len(tareas_negativas)} negativos.\")\n",
    "else:\n",
    "    df_tareas_imagenes = pd.DataFrame()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# FASE 3: DESCARGA DE SECUENCIAS\n",
    "# ==============================================================================\n",
    "if not df_tareas_imagenes.empty:\n",
    "    ruta_base_guardado = \"../data/raw/imagenes_satelitales/\"\n",
    "    os.makedirs(ruta_base_guardado, exist_ok=True)\n",
    "    print(\"\\n--- Fase 3: Iniciando la descarga de secuencias de imágenes satelitales ---\")\n",
    "    print(\"Este proceso puede tardar varios minutos.\")\n",
    "\n",
    "    for index, tarea in df_tareas_imagenes.iterrows():\n",
    "        fecha = tarea['date']\n",
    "        hora_central_utc = parse_hora_a_utc(tarea['hora_aprox'])\n",
    "        \n",
    "        if hora_central_utc is not None:\n",
    "            nombre_carpeta_evento = f\"{ruta_base_guardado}{fecha.strftime('%Y-%m-%d')}_{('granizo' if tarea['granizo'] == 1 else 'no_granizo')}/\"\n",
    "            if os.path.exists(nombre_carpeta_evento) and len(os.listdir(nombre_carpeta_evento)) >= 5:\n",
    "                print(f\"\\nSecuencia para {fecha.strftime('%Y-%m-%d')} ya completa. Saltando.\")\n",
    "                continue\n",
    "            \n",
    "            os.makedirs(nombre_carpeta_evento, exist_ok=True)\n",
    "            print(f\"\\nProcesando evento: {fecha.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            for i in range(-2, 3):\n",
    "                hora_utc_actual = (hora_central_utc + i + 24) % 24 # Se asegura que el resultado sea siempre positivo\n",
    "                try:\n",
    "                    año = fecha.year\n",
    "                    dia_del_año = fecha.dayofyear\n",
    "                    prefix = f\"ABI-L2-CMIPF/{año}/{dia_del_año:03d}/{hora_utc_actual:02d}/\"\n",
    "                    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "                    \n",
    "                    archivo_encontrado = None\n",
    "                    if 'Contents' in response:\n",
    "                        for file in response['Contents']:\n",
    "                            if 'C13' in file['Key']:\n",
    "                                archivo_encontrado = file['Key']\n",
    "                                break\n",
    "                    \n",
    "                    if archivo_encontrado:\n",
    "                        nombre_archivo_local = f\"{nombre_carpeta_evento}{fecha.strftime('%Y-%m-%d')}_{hora_utc_actual:02d}00_UTC_C13.nc\"\n",
    "                        if not os.path.exists(nombre_archivo_local):\n",
    "                            print(f\"  -> Descargando imagen para las {hora_utc_actual:02d}:00 UTC...\")\n",
    "                            s3.download_file(bucket_name, archivo_encontrado, nombre_archivo_local)\n",
    "                    else:\n",
    "                        print(f\"  -> No se encontraron imágenes para las {hora_utc_actual:02d}:00 UTC.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  -> ERROR procesando la hora {hora_utc_actual:02d}:00 UTC. Error: {e}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "    print(\"\\n--- Proceso de descarga de secuencias finalizado ---\")\n",
    "else:\n",
    "    print(\"\\nNo se ejecutó la Fase 3 porque no se generaron tareas de descarga.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06409529-eeb3-473f-8a25-87b69c438178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
